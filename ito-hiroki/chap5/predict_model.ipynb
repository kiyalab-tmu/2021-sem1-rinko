{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confidential-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "\n",
    "from dataset import TimeMachineData, TimeMachineDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaningful-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structured-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hidden_dim=128, nlayers=2):\n",
    "        super(RNN, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.rnn = nn.RNN(emb_dim, hidden_dim, 2)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "        nn.init.normal_(self.embed.weight, std=0.01)\n",
    "\n",
    "        nn.init.normal_(self.rnn.weight_ih_l0, std=1 / math.sqrt(emb_dim))\n",
    "        nn.init.normal_(self.rnn.weight_hh_l0, std=1 / math.sqrt(emb_dim))\n",
    "        nn.init.zeros_(self.rnn.bias_ih_l0)\n",
    "        nn.init.zeros_(self.rnn.bias_hh_l0)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        out = self.embed(inputs)\n",
    "        out = self.dropout1(out)\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return Variable(weight.new(self.nlayers, bsz, self.hidden_dim).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emerging-sensitivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i):\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i : i + seq_len]\n",
    "    target = source[i + 1 : i + 1 + seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "judicial-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = f\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "temperature = 1.0\n",
    "bptt = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "desirable-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "timemachine = TimeMachineData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "celtic-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = timemachine.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "persistent-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embed): Embedding(94, 128)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (rnn): RNN(128, 128, num_layers=2)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=128, out_features=94, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RNN(ntokens)\n",
    "model.load_state_dict(torch.load(\"rnn_thetimemachine.pth\"))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blocked-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path=\"../data/TheTimeMachine/35-0.txt\"\n",
    "dict_path=\"../data/TheTimeMachine/char.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "disciplinary-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.read_csv(dict_path)\n",
    "char2idx = dict(zip(word_df[\"word\"], word_df.index))\n",
    "idx2char = dict(zip(word_df.index, word_df[\"word\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-indication",
   "metadata": {},
   "source": [
    "# multi char input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hispanic-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A queer thing I soon\"\n",
    "text = [char2idx[\"<BOS>\"]] + [char2idx[char] for char in text.strip()]\n",
    "data = [text]\n",
    "data = torch.from_numpy(np.array(sum(data, []))).long()\n",
    "data = torch.unsqueeze(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unnecessary-inventory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 31,  3, 51, 15,  4,  4, 11,  3,  5, 12,  9,  8, 19,  3, 26,  3, 10,\n",
       "          7,  7,  8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sticky-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "harmful-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 31,  3, 51, 15,  4,  4, 11,  3,  5, 12,  9,  8, 19,  3, 26,  3, 10,\n",
       "          7,  7,  8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sound-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = model.init_hidden(data.shape[1])\n",
    "result = data.cpu().numpy().tolist()[0]\n",
    "for i in range(100):\n",
    "    with torch.no_grad():\n",
    "        output, hidden = model(data, hidden)\n",
    "        \n",
    "        word_weights = output.squeeze().data.div(1.0).exp().cpu()\n",
    "        word_idx = torch.multinomial(word_weights, 1).squeeze()\n",
    "        \n",
    "        result += word_idx.cpu().numpy().tolist()\n",
    "        data = word_idx.reshape(1, -1)\n",
    "        \n",
    "        if 0 in word_idx.cpu().numpy().tolist():\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "toxic-minnesota",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS>A queer thing I soonavTun- kt/enaoS<EOS>Y 6kXnihkddwehem tup<BOS>it. /'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([idx2char[x] for x in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-illinois",
   "metadata": {},
   "source": [
    "# single char input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hispanic-segment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>could. The Daggh, Ge as<EOS>\n",
      "<BOS>aud see1l. Sut’cifh’illiches, and in the rooldend, and dard—a was diman (bonay :ape. I have no to me\n",
      "<BOS>intomes, por and ito<EOS>\n",
      "<BOS>in the Mdevers think, aüsuvated to ag. The<EOS>\n",
      "<BOS>hand us sole#tress foscals a gent made. Wo the Way<EOS>\n",
      "<BOS>That I stoidging enough me heexe<EOS>\n",
      "<BOS>the<EOS>\n",
      "<BOS>of all the minder, hud mrying latheors, I had wother and douss hit sour. bat they was reworal be. Th\n",
      "<BOS>“foon I wan indeld ot and htatchess ser more tto dist. Hade as riwrle littre heey un<EOS>\n",
      "<BOS>they; I gotæ wele grave the<EOS>\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    text = [0]\n",
    "    data = [text]\n",
    "    data = torch.from_numpy(np.array(sum(data, []))).long()\n",
    "    data = torch.unsqueeze(data, 0)\n",
    "    data = data.to(device)\n",
    "    \n",
    "    hidden = model.init_hidden(1)\n",
    "    result = [0]\n",
    "    for i in range(100):\n",
    "        output, hidden = model(data, hidden)\n",
    "        \n",
    "        # word_idx = torch.argmax(output, dim=2).item()\n",
    "        word_weights = output.squeeze().data.div(1.0).exp().cpu()\n",
    "        word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "        \n",
    "        data.data.fill_(word_idx)\n",
    "        result.append(word_idx.item())\n",
    "        if word_idx == 1:\n",
    "            break\n",
    "    print(\"\".join([idx2char[x] for x in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-tunisia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
