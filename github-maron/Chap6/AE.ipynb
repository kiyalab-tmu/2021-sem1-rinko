{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense_enc1 = nn.Linear(28*28, 256)\n",
    "        self.dense_enc2 = nn.Linear(256, 64)\n",
    "        self.dense_dec1 = nn.Linear(64, 256)\n",
    "        self.dense_dec2 = nn.Linear(256, 28*28)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.dense_enc1(x))\n",
    "        x = F.relu(self.dense_enc2(x))\n",
    "        x = F.relu(self.dense_dec1(x))\n",
    "        x = torch.sigmoid(self.dense_dec2(x))\n",
    "        return x\n",
    "       \n",
    "batch_size = 256\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x.view(-1))])\n",
    "\n",
    "fashion_mnist_train = FashionMNIST(\"FashionMNIST\", train=True, download=True, transform=transform)\n",
    "fashion_mnist_test = FashionMNIST(\"FashionMNIST\", train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(fashion_mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(fashion_mnist_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, train_loss : 0.0275\n",
      "epoch : 1, train_loss : 0.0157\n",
      "epoch : 2, train_loss : 0.0137\n",
      "epoch : 3, train_loss : 0.0126\n",
      "epoch : 4, train_loss : 0.0121\n",
      "epoch : 5, train_loss : 0.0116\n",
      "epoch : 6, train_loss : 0.0114\n",
      "epoch : 7, train_loss : 0.0111\n",
      "epoch : 8, train_loss : 0.0111\n",
      "epoch : 9, train_loss : 0.0109\n",
      "epoch : 10, train_loss : 0.0108\n",
      "epoch : 11, train_loss : 0.0107\n",
      "epoch : 12, train_loss : 0.0106\n",
      "epoch : 13, train_loss : 0.0105\n",
      "epoch : 14, train_loss : 0.0105\n",
      "epoch : 15, train_loss : 0.0104\n",
      "epoch : 16, train_loss : 0.0104\n",
      "epoch : 17, train_loss : 0.0103\n",
      "epoch : 18, train_loss : 0.0102\n",
      "epoch : 19, train_loss : 0.0103\n"
     ]
    }
   ],
   "source": [
    "net = AE()\n",
    "net.to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "epoch_num = 20\n",
    "running_loss = np.zeros(epoch_num)\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs = data[0].to(device)\n",
    "        optimizer.zero_grad() \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(inputs, outputs) \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        running_loss[epoch] += loss.item()       \n",
    "        \n",
    "    running_loss[epoch] /= len(train_loader)\n",
    "\n",
    "    print(\"epoch : %d, train_loss : %.4lf\" % (epoch, running_loss[epoch]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, _ = next(iter(test_loader))\n",
    "x = x.to(device)\n",
    "\n",
    "x_rec = net(x)\n",
    "\n",
    "for i, image in enumerate([x, x_rec]):\n",
    "    #image = image.view(28, 28).detach().numpy()\n",
    "    image = image.view(-1, 28, 28)\n",
    "    image = image.squeeze().detach().numpy()\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
