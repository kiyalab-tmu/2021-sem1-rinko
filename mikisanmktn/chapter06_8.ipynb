{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.models.inception import inception_v3\n",
    "from scipy import linalg\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(nn.Module):\n",
    "    def __init__(self, nz, ngf):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_score(inception_model, gan_model, test_dl=None, fixed_z=None):\n",
    "    preds = []\n",
    "    if fixed_z != None:\n",
    "        for i in range(fixed_z.shape[0]):\n",
    "            fakes = gan_model(fixed_z[i])\n",
    "            pred = get_pred(up(fakes), inception_model)\n",
    "            preds.append(pred)\n",
    "        preds = np.array(preds).reshape(-1,pred.shape[1])\n",
    "    if test_dl != None:\n",
    "        for datas, targets in tqdm(test_dl):\n",
    "            if datas.shape[0] < TEST_BATCH_SIZE:\n",
    "                break\n",
    "            pred = get_pred(up(datas).to(device), inception_model)\n",
    "            preds.append(pred)\n",
    "        preds = np.array(preds)\n",
    "        preds = preds.reshape(-1,pred.shape[1])\n",
    "        \n",
    "    \n",
    "    py = preds.mean(0)\n",
    "    scores = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        scores.append(entropy(preds[i], py))\n",
    "    inception_score = np.exp(np.mean(scores))\n",
    "\n",
    "    return inception_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_activation_statistics(act):\n",
    "    mu = np.mean(act, axis=0)\n",
    "    sigma = np.cov(act, rowvar=False)\n",
    "    return mu, sigma\n",
    "\n",
    "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
    "    mu1 = np.atleast_1d(mu1)\n",
    "    mu2 = np.atleast_1d(mu2)\n",
    "\n",
    "    sigma1 = np.atleast_2d(sigma1)\n",
    "    sigma2 = np.atleast_2d(sigma2)\n",
    "\n",
    "    assert mu1.shape == mu2.shape, \\\n",
    "        'Training and test mean vectors have different lengths'\n",
    "    assert sigma1.shape == sigma2.shape, \\\n",
    "        'Training and test covariances have different dimensions'\n",
    "\n",
    "    diff = mu1 - mu2\n",
    "\n",
    "    # Product might be almost singular\n",
    "    covmean, _ = linalg.sqrtm(sigma1.dot(sigma2), disp=False)\n",
    "    if not np.isfinite(covmean).all():\n",
    "        msg = ('fid calculation produces singular product; '\n",
    "               'adding %s to diagonal of cov estimates') % eps\n",
    "        print(msg)\n",
    "        offset = np.eye(sigma1.shape[0]) * eps\n",
    "        covmean = linalg.sqrtm((sigma1 + offset).dot(sigma2 + offset))\n",
    "\n",
    "    # Numerical error might give slight imaginary component\n",
    "    if np.iscomplexobj(covmean):\n",
    "        if not np.allclose(np.diagonal(covmean).imag, 0, atol=1e-3):\n",
    "            m = np.max(np.abs(covmean.imag))\n",
    "            raise ValueError('Imaginary component {}'.format(m))\n",
    "        covmean = covmean.real\n",
    "\n",
    "    tr_covmean = np.trace(covmean)\n",
    "\n",
    "    return (diff.dot(diff) + np.trace(sigma1) +\n",
    "            np.trace(sigma2) - 2 * tr_covmean)\n",
    "\n",
    "def FID(inception_model, gan_model, test_dl, fixed_z):\n",
    "    bootstrap=True\n",
    "    n_bootstraps=10\n",
    "    \n",
    "    real_preds = []\n",
    "    if test_dl != None:\n",
    "        for datas, targets in tqdm(test_dl):\n",
    "            if datas.shape[0] < TEST_BATCH_SIZE:\n",
    "                break\n",
    "            pred = get_pred(up(datas).to(device), inception_model, fid=True)\n",
    "            real_preds.append(pred)\n",
    "        real_preds = np.array(real_preds).reshape(-1,pred.shape[1])\n",
    "    fake_preds = []\n",
    "    if fixed_z != None:\n",
    "        for i in range(fixed_z.shape[0]):\n",
    "            fakes = gan_model(fixed_z[i])\n",
    "            pred = get_pred(up(fakes), inception_model, fid=True)\n",
    "            fake_preds.append(pred)\n",
    "        fake_preds = np.array(fake_preds).reshape(-1,pred.shape[1])\n",
    "    \n",
    "    n_bootstraps = n_bootstraps if bootstrap else 1\n",
    "    fid_values = np.zeros((n_bootstraps))\n",
    "    with tqdm(range(n_bootstraps), desc='FID') as bar:\n",
    "        for i in bar:\n",
    "            act1_bs = real_preds[np.random.choice(real_preds.shape[0], real_preds.shape[0], replace=True)]\n",
    "            act2_bs = fake_preds[np.random.choice(fake_preds.shape[0], fake_preds.shape[0], replace=True)]\n",
    "            m1, s1 = calculate_activation_statistics(act1_bs)\n",
    "            m2, s2 = calculate_activation_statistics(act2_bs)\n",
    "            fid_values[i] = calculate_frechet_distance(m1, s1, m2, s2)\n",
    "            bar.set_postfix({'mean': fid_values[:i+1].mean()})\n",
    "\n",
    "    return fid_values.mean(), fid_values.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_mmd_averages(codes_g, codes_r, n_subsets=50, subset_size=1000,\n",
    "                            ret_var=True, output=sys.stdout, **kernel_args):\n",
    "    m = min(codes_g.shape[0], codes_r.shape[0])\n",
    "    mmds = np.zeros(n_subsets)\n",
    "    if ret_var:\n",
    "        vars = np.zeros(n_subsets)\n",
    "    choice = np.random.choice\n",
    "\n",
    "    with tqdm(range(n_subsets), desc='MMD', file=output) as bar:\n",
    "        for i in bar:\n",
    "            g = codes_g[choice(len(codes_g), subset_size, replace=False)]\n",
    "            r = codes_r[choice(len(codes_r), subset_size, replace=False)]\n",
    "            o = polynomial_mmd(g, r, **kernel_args, var_at_m=m, ret_var=ret_var)\n",
    "            if ret_var:\n",
    "                mmds[i], vars[i] = o\n",
    "            else:\n",
    "                mmds[i] = o\n",
    "            bar.set_postfix({'mean': mmds[:i+1].mean()})\n",
    "    return (mmds, vars) if ret_var else mmds\n",
    "def polynomial_mmd(codes_g, codes_r, degree=3, gamma=None, coef0=1,\n",
    "                   var_at_m=None, ret_var=True):\n",
    "    # use  k(x, y) = (gamma <x, y> + coef0)^degree\n",
    "    # default gamma is 1 / dim\n",
    "    X = codes_g\n",
    "    Y = codes_r\n",
    "\n",
    "    K_XX = polynomial_kernel(X, degree=degree, gamma=gamma, coef0=coef0)\n",
    "    K_YY = polynomial_kernel(Y, degree=degree, gamma=gamma, coef0=coef0)\n",
    "    K_XY = polynomial_kernel(X, Y, degree=degree, gamma=gamma, coef0=coef0)\n",
    "\n",
    "    return _mmd2_and_variance(K_XX, K_XY, K_YY,\n",
    "                              var_at_m=var_at_m, ret_var=ret_var)\n",
    "def _sqn(arr):\n",
    "    flat = np.ravel(arr)\n",
    "    return flat.dot(flat)\n",
    "def _mmd2_and_variance(K_XX, K_XY, K_YY, unit_diagonal=False,\n",
    "                       mmd_est='unbiased', block_size=1024,\n",
    "                       var_at_m=None, ret_var=True):\n",
    "    # based on\n",
    "    # https://github.com/dougalsutherland/opt-mmd/blob/master/two_sample/mmd.py\n",
    "    # but changed to not compute the full kernel matrix at once\n",
    "    m = K_XX.shape[0]\n",
    "    assert K_XX.shape == (m, m)\n",
    "    assert K_XY.shape == (m, m)\n",
    "    assert K_YY.shape == (m, m)\n",
    "    if var_at_m is None:\n",
    "        var_at_m = m\n",
    "\n",
    "    # Get the various sums of kernels that we'll use\n",
    "    # Kts drop the diagonal, but we don't need to compute them explicitly\n",
    "    if unit_diagonal:\n",
    "        diag_X = diag_Y = 1\n",
    "        sum_diag_X = sum_diag_Y = m\n",
    "        sum_diag2_X = sum_diag2_Y = m\n",
    "    else:\n",
    "        diag_X = np.diagonal(K_XX)\n",
    "        diag_Y = np.diagonal(K_YY)\n",
    "\n",
    "        sum_diag_X = diag_X.sum()\n",
    "        sum_diag_Y = diag_Y.sum()\n",
    "\n",
    "        sum_diag2_X = _sqn(diag_X)\n",
    "        sum_diag2_Y = _sqn(diag_Y)\n",
    "\n",
    "    Kt_XX_sums = K_XX.sum(axis=1) - diag_X\n",
    "    Kt_YY_sums = K_YY.sum(axis=1) - diag_Y\n",
    "    K_XY_sums_0 = K_XY.sum(axis=0)\n",
    "    K_XY_sums_1 = K_XY.sum(axis=1)\n",
    "\n",
    "    Kt_XX_sum = Kt_XX_sums.sum()\n",
    "    Kt_YY_sum = Kt_YY_sums.sum()\n",
    "    K_XY_sum = K_XY_sums_0.sum()\n",
    "\n",
    "    if mmd_est == 'biased':\n",
    "        mmd2 = ((Kt_XX_sum + sum_diag_X) / (m * m)\n",
    "                + (Kt_YY_sum + sum_diag_Y) / (m * m)\n",
    "                - 2 * K_XY_sum / (m * m))\n",
    "    else:\n",
    "        assert mmd_est in {'unbiased', 'u-statistic'}\n",
    "        mmd2 = (Kt_XX_sum + Kt_YY_sum) / (m * (m-1))\n",
    "        if mmd_est == 'unbiased':\n",
    "            mmd2 -= 2 * K_XY_sum / (m * m)\n",
    "        else:\n",
    "            mmd2 -= 2 * (K_XY_sum - np.trace(K_XY)) / (m * (m-1))\n",
    "\n",
    "    if not ret_var:\n",
    "        return mmd2\n",
    "\n",
    "    Kt_XX_2_sum = _sqn(K_XX) - sum_diag2_X\n",
    "    Kt_YY_2_sum = _sqn(K_YY) - sum_diag2_Y\n",
    "    K_XY_2_sum = _sqn(K_XY)\n",
    "\n",
    "    dot_XX_XY = Kt_XX_sums.dot(K_XY_sums_1)\n",
    "    dot_YY_YX = Kt_YY_sums.dot(K_XY_sums_0)\n",
    "\n",
    "    m1 = m - 1\n",
    "    m2 = m - 2\n",
    "    zeta1_est = (\n",
    "        1 / (m * m1 * m2) * (\n",
    "            _sqn(Kt_XX_sums) - Kt_XX_2_sum + _sqn(Kt_YY_sums) - Kt_YY_2_sum)\n",
    "        - 1 / (m * m1)**2 * (Kt_XX_sum**2 + Kt_YY_sum**2)\n",
    "        + 1 / (m * m * m1) * (\n",
    "            _sqn(K_XY_sums_1) + _sqn(K_XY_sums_0) - 2 * K_XY_2_sum)\n",
    "        - 2 / m**4 * K_XY_sum**2\n",
    "        - 2 / (m * m * m1) * (dot_XX_XY + dot_YY_YX)\n",
    "        + 2 / (m**3 * m1) * (Kt_XX_sum + Kt_YY_sum) * K_XY_sum\n",
    "    )\n",
    "    zeta2_est = (\n",
    "        1 / (m * m1) * (Kt_XX_2_sum + Kt_YY_2_sum)\n",
    "        - 1 / (m * m1)**2 * (Kt_XX_sum**2 + Kt_YY_sum**2)\n",
    "        + 2 / (m * m) * K_XY_2_sum\n",
    "        - 2 / m**4 * K_XY_sum**2\n",
    "        - 4 / (m * m * m1) * (dot_XX_XY + dot_YY_YX)\n",
    "        + 4 / (m**3 * m1) * (Kt_XX_sum + Kt_YY_sum) * K_XY_sum\n",
    "    )\n",
    "    var_est = (4 * (var_at_m - 2) / (var_at_m * (var_at_m - 1)) * zeta1_est\n",
    "               + 2 / (var_at_m * (var_at_m - 1)) * zeta2_est)\n",
    "\n",
    "    return mmd2, var_est\n",
    "\n",
    "def KID(inception_model, gan_model, test_dl, fixed_z):\n",
    "    real_preds = []\n",
    "    if test_dl != None:\n",
    "        for datas, targets in tqdm(test_dl):\n",
    "            if datas.shape[0] < TEST_BATCH_SIZE:\n",
    "                break\n",
    "            pred = get_pred(up(datas).to(device), inception_model, fid=True)\n",
    "            real_preds.append(pred)\n",
    "        real_preds = np.array(real_preds).reshape(-1,pred.shape[1])\n",
    "    fake_preds = []\n",
    "    if fixed_z != None:\n",
    "        for i in range(fixed_z.shape[0]):\n",
    "            fakes = gan_model(fixed_z[i])\n",
    "            pred = get_pred(up(fakes), inception_model, fid=True)\n",
    "            fake_preds.append(pred)\n",
    "        fake_preds = np.array(fake_preds).reshape(-1,pred.shape[1])\n",
    "    \n",
    "    kid_values = polynomial_mmd_averages(real_preds, fake_preds, n_subsets=100)\n",
    "    \n",
    "    return kid_values[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(x, model, fid=False):\n",
    "    x = model(x)\n",
    "    if fid:\n",
    "        pred = x.cpu().detach().numpy()\n",
    "    else:\n",
    "        pred = F.softmax(x).data.cpu().numpy()\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE = 128\n",
    "nz = 100\n",
    "ngf = 64\n",
    "device = f\"cuda:{0}\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5),(0.5))])\n",
    "\n",
    "test_dataset = datasets.CelebA(root='/home/image/CelebA/data/', split=\"test\", target_type='attr', download=False, transform=transform)\n",
    "test_dl = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "dcgan = DCGAN(nz,ngf).to(device)\n",
    "dcgan.load_state_dict(torch.load(\"checkpoints/DCGAN_CelebA_netG.pth\"))\n",
    "inception_model = inception_v3(pretrained=True).to(device)\n",
    "inception_model.eval()\n",
    "\n",
    "fixed_z = torch.randn(156, TEST_BATCH_SIZE, nz, 1, 1, device=device).requires_grad_()\n",
    "\n",
    "up = nn.Upsample(size=(128, 128), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]/home/miki225/miki/myvenv/rinkovenv/lib/python3.6/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/home/miki225/miki/myvenv/rinkovenv/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      " 99%|█████████▉| 155/156 [00:54<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.160202\n",
      "11.840354\n"
     ]
    }
   ],
   "source": [
    "real_is = Inception_score(inception_model, dcgan, test_dl=test_dl)\n",
    "print(real_is)\n",
    "fake_is = Inception_score(inception_model, dcgan, fixed_z=fixed_z)\n",
    "print(fake_is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]/home/miki225/miki/myvenv/rinkovenv/lib/python3.6/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      " 99%|█████████▉| 155/156 [00:52<00:00,  2.96it/s]\n",
      "FID: 100%|██████████| 10/10 [00:15<00:00,  1.52s/it, mean=404]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(403.90210336574563, 8.99333050911341)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fid = FID(inception_model, dcgan, test_dl=test_dl, fixed_z=fixed_z)\n",
    "print(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]/home/miki225/miki/myvenv/rinkovenv/lib/python3.6/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      " 99%|█████████▉| 155/156 [00:51<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD: 100%|██████████| 100/100 [00:06<00:00, 15.04it/s, mean=3.88]\n",
      "3.8781415670870865\n"
     ]
    }
   ],
   "source": [
    "kid = KID(inception_model, dcgan, test_dl=test_dl, fixed_z=fixed_z)\n",
    "print(kid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wgan = DCGAN(nz,ngf).to(device)\n",
    "wgan.load_state_dict(torch.load(\"checkpoints/WGAN_CelebA_netG.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]/home/miki225/miki/myvenv/rinkovenv/lib/python3.6/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "/home/miki225/miki/myvenv/rinkovenv/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n",
      " 99%|█████████▉| 155/156 [06:28<00:02,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.160202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.197154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 155/156 [00:58<00:00,  2.64it/s]\n",
      "FID: 100%|██████████| 10/10 [00:09<00:00,  1.00it/s, mean=538]\n",
      "  0%|          | 0/156 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(538.4749462789041, 8.901178003748322)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 155/156 [00:53<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMD: 100%|██████████| 100/100 [00:05<00:00, 18.39it/s, mean=4.93]\n",
      "4.9309125899499495\n"
     ]
    }
   ],
   "source": [
    "real_is = Inception_score(inception_model, wgan, test_dl=test_dl)\n",
    "print(real_is)\n",
    "fake_is = Inception_score(inception_model, wgan, fixed_z=fixed_z)\n",
    "print(fake_is)\n",
    "\n",
    "fid = FID(inception_model, wgan, test_dl=test_dl, fixed_z=fixed_z)\n",
    "print(fid)\n",
    "\n",
    "kid = KID(inception_model, wgan, test_dl=test_dl, fixed_z=fixed_z)\n",
    "print(kid)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3810870ca7cf897a1d5ef461b233ac845775f0955dba453ad352eec6137a516"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('rinkovenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
